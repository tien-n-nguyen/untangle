\section{Context-aware, Graph-based, Code Change, Clustering Learning Model}
\label{clustering-model:sec}

Let us explain in details our approach. While the first step (building
the multi-version {\mvpdg}) is presented in
Section~\ref{overview:sec}, we present in this section our
context-aware, graph-based, code change (CC) clustering learning
model.  This step has two tasks: 1) Taking the computed {\mvpdg} to
learn the code change representation vectors (embeddings), and 2)
performing clustering on those embeddings to cluster the changed
statements.  During training, we have the ground truth on the clusters
of the changed statements, thus, we have the cluster labels (concern
1, concern 2, etc.) for the changed nodes in {\mvpdg}. During
predicting (i.e., clustering), the input {\mvpdg} will be fed into the
trained clustering learning model to produce the cluster labels for
the changed nodes/statements. For the given {\mvpdg}, the number of
clusters is unknown to the model, and it decides that number via its
agglomerative clustering. Let us detail the two tasks of our CC
clustering learning model.

%traing and predicting


\subsection{Context-aware, Code Change Representation Learning}
\label{vector:sec}

\begin{figure*}[t]
	\centering \includegraphics[width=5.8in]{figures/STEP_2-new.png}
	\vspace{-6pt}
	\caption{Context-aware, Graph-based, Code Change, Clustering Learning Model}
	\label{fig:step-2}
\end{figure*}

The goal of this task is to build the vector representations (i.e.,
embeddings) for the code changes (i.e., the changed statements)
represented by the changed nodes in {\mvpdg}. A characteristic of the
embeddings for the code changes is {\em context-aware} or {\em
  contextualized}. That is, the same code change in different contexts
will have different embeddings.

\subsubsection{{\bf Label, Graph-based Convolutional Network (Label-GCN)}}

To achieve that, {\tool} first feeds the multi-version {\mvpdg} to a
graph-based, deep learning model to learn the contextualized
embeddings for the nodes in the graph. Because {\mvpdg} contains the
labels (i.e., $i$, $j$, $(i,j)$) representing the (un)changes of the
nodes, to better learn the useful information from the node features
with the labels, {\tool} uses Label-GCN~\cite{} to model the graph.


%Before doing the clustering, in this step, \tool needs to get the representation vector $v'_c$ for each changed node $n_c$ first. To achieve it, \tool firstly put the {\mvpdg} into a graph-based deep learning model to learn the representation vector for each node in the graph. Because the {\mvpdg} contains the labels for each node, to better learn the useful information from the node features with the labels, \tool uses the Lable-GCN \cite{} model to do so.

%In the Label-GCN, similarly to the normal GCN \cite{}, it takes the graph with the node features as the input and generates the representation vector for each node as the output. Compared with normal GCN, it also accepts the node labels in the first layer. In this case, when dealing with a central node, the model is allowed to see the labels of the neighbors, and the labels can then become part of the feature vector. With this, Label-GCN calculates the representation vectors in the first layer as follow:

Simlar to GCN~\cite{yi}, Label-GCN~\cite{yi} takes the graph with the
node features as the input and produce the vectors for the nodes, when
considering the features of the neighboring nodes of each node.  In
addition, the Label-GCN also accepts the node labels in the first
layer. For the node under consideration, it can take the labels of the
neighboring nodes in account as part of the feature vectors. With
that, it computes the vectors in the first layer as follows:
\begin{equation}\label{eq1}
	H^1 = \sigma [(\hat{A}X-diag(\hat{A})\sum_{j=1}^{K}e_je^T_j)W^0]
\end{equation}
\begin{equation}\label{eq2}
	\hat{A} = \tilde{D}^{-\frac{1}{2}}\tilde{A}\tilde{D}^{-\frac{1}{2}}
\end{equation}
\begin{equation}\label{eq3}
	\tilde{A} = A + I
\end{equation}
Where $H$ is the output for the first hidden layer; $A$ is the
adjacency matrix; $\tilde{D}$ is the diagonal node degree matrix; $W$
is the weight matrix; $X$ is the input and $X \in R^{nx(d+K)}$; $n$ is
the number of nodes; $d$ is the dimension of node features; $K$ is the
number of types of node labels in the input; $e_je^T_j$ a single-entry
matrix; and $-diag(\hat{A})\sum_{j=1}^{K}e_je^T_j$ is used to
eliminates the self-loops for the components of the feature vectors
corresponding to the labels.

%After the first layer, the result layers in Label-GCN follow the same process as normal GCN to calculate the hidden status. The formula of the following layers is as follow:

In Label-GCN, the following layers after the first one follows the
same process as in the GCN model~\cite{yi} to compute the hidden
states. The computation in a following layer $l$ is as follows:
\begin{equation}\label{eq4}
	H^{l+1} = \sigma (\hat{A}H^lW^l), l \geq 1 
\end{equation}

\subsubsection{{\bf Using Label-GCN to model {\mvpdg}}}
\label{sec:preprocess}
This section explains how we process the multi-version {\mvpdg} to
produce the input for the Label-GCN model. For each node $n$ of a
statement $s$ in {\mvpdg}, we break it down into the code tokens $t$,
and build the word embeddings $e_t$ via Glove~\cite{yi}. The vector
for the node $n$ is the average vector $Avg_n$ of the vectors of all
the tokens $t$ within the corresponding statement $s$. Because each
node $n$ has an (un)-changed label $i$, $j$, or $(i,j)$ for the
versions, we combine $Avg_n$ with the one-hot vector of the length 3
representing the labels $i$, $j$, or $(i,j)$. As a result, the
combined vector $v_n$ (with the length of $len(Avg_n)$+3) is the node
feature vector for $n$. Then, we build the graph with the same
structure as {\mvpdg} in which a node $n$ is replaced with the node
vector $v_n$, and feed that graph to the Labe-GCN model to obtain the
embeddings $V_n$ for all the nodes in {\mvpdg}.

%In \tool, we firstly use GloVe \cite{} to learn the word embedding $e_t$ for each token $t$ in each statement $n$ in the source code. Because in {\mvpdg}, each node is a statement $n$, we calculate the average embedding $Avg_n$ for each node based on the word embedding $e_t$ for each token inside of the statement. By combining $Avg_n$ with the known label $i$, $j$, and $i, j$ as one-hot labels, node embedding length become $len(Avg_n) + 3$ and \tool regards the combined vector $Avg'_n$ as the node feature vector for node $n$. Then, we put the {\mvpdg} with the node feature vectors $Avg'_n$ into the Label-GCN model to get the representation vector $v$ for each node $n$ in the graph.

\subsubsection{Building Contexts and Contextualized Embeddings}
After using Label-GCN, we obtain the vectors $V_n$ for all the nodes
$n$. For a changed node $n_c$, we collect the nodes in its context
$ctx$ (i.e., all un-changed nodes that are the $k$-hop neighbor of $n$
together with all the inducing edges among them. We merge all the
vectors for the nodes in $ctx$ into a matrix accordingly to the order
of the statements in source code. We then use a fully-connected layer
to learn the vector $v_{ctx}$ representing the context $ctx$ of the
changed node $n_c$.

Finally, we perform a cross-product between the vector $v_{ctx}$ and
the vector $V{n_c}$ for a changed node $n_c$, to produce the
contextualized embedding $V^{*}_{n_c}$ for $n_c$.

%After we have $v$ for each node $n$, for each changed node $n_c$ in $n$, we pick the context for node $n$ which are the un-changed nodes $n_{uc}$ in $k$-hops neighbors. By merging all representation vectors $v_{uc}$ in the context based on the original node orders as a matrix, \tool uses a fully-connected layer to learn the context representation vector $v_{ctx}$ for node $n_c$. In the end, to get the final representation vector $v'_c$ for the changed node $n_c$, we uses the cross-product to merge $v_c$ and $v_{ctx}$.

Figure~\ref{fig:step-2} illustrates the process of building the
contextualized embeddings for the code change example in
Figure~\ref{fig:multi-version-pdg}. $S_3$, ..., $S_7$ are the
statements at the corresponding lines. After building {\mvpdg},
{\tool} goes through the process described in
Section~\ref{sec:preprocess} (i.e., building token embeddings,
statement embeddings, and combining with the labels) to produce the
node vectors $v_n$ for all the nodes in {\mvpdg}. The Label-GCN model
takes the graph with the vectors $v_n$ to produce the graph with the
same structure in which each node is represented by the vector $V_n$
($V_3$, ..., $V_7$). Let us use the node for $V_6$ as an example.  The
context of 1-hop neighbors includes $V_3$, $V_4$, and $V_7$. By
merging those vectors as a matrix and passing through a fully
connected layer, we obtain the vector $v_{ctx}$ representing the 1-hop
context for $V_6$. The cross-product vector  $V^{*}_6$ = $v_{ctx}$ $\times$ $V_6$
is the contextualized embedding representing the changed statement
$S_6$.


%Figure \ref{fig:step-2} can be an example to show how this step works in the \tool. First of all, \tool has the {\mvpdg} which is also shown in figure \ref{fig:multi-version-pdg} as the input. The $S3-S7$ represents the statement in $line-3$ to $line-7$. Bypassing through the Label-GCN, \tool gets the same structured graph with representation vectors $V3-V7$ for each node $S3-S7$.

%Then, we pick the added node $S6$ as an example. The context includes the un-changed nodes $S3, S4, S7$, and the representation vectors for them are $V3, V4, V7$. By putting them as a matrix and passing through a fully connected layer, we have the context representation vector $v_{ctx}$ for $S6$.

%Then, we use the cross-product to calculate $v_{ctv} x V6$. The calculation result is the final code change representation vector $v'_{S6}$ for node $S6$.  

\subsection{Code Change Clustering Learning}
\label{clustering:sec}

After building the contextualized embeddings $V^{*}_{n_c}$ for all the
changed nodes in {\mvpdg}, {\tool} performs clustering on those
vectors to untangle the commit. We have modified the hierarchical
agglomerative clustering algorithm~\cite{yi} to make it a deep
learning model to cluster those vectors based on the clusters of the
changes in the training data. The training process for our CC
clustering learning model works  as follows.

{\em \underline{Step 1.}} We first consider each changed node $n_c$ as a
separate cluster $CL_c$.

{\em \underline{Step 2.}} We merge any two clusters whose cluster
similarity is the largest and higher than a threshold $T$.

{\em \underline{Step 3.}} We continue the merging to form larger
clusters until there is no cluster that can be merged. After this
step, we obtain the predicted clusters $CL$ at the current iteration.

{\em \underline{Step 4.}} The predicted clusters $CL$ at this iteration
are compared against the correct clusters $CL_{oracle}$ in the ground
truth. We develop a loss function for our training to minimize the
differences between the predicted clusters $CL$ and the correct
clusters $CL_{oracle}$. The parameters and the trainable threshold $T$
will be updated accordingly to the loss function for the next
iteration. The training will stop when the process converges and we
obtain the most suitable parameters for our learning model.

\subsubsection*{{\bf Cluster Similarity}} To compute the similarity between
two clusters $CL_1$ and $CL_2$, we take all the pairs of the changed
nodes $(n_1,n_2)$ where $n_1 \in CL_1$ and $n_2 \in CL_2$. We
then compute the cosine similarity between the corresponding vectors
$V^{*}_{n_1}$ and $V^{*}_{n_2}$ for each pair. The similarity between
two clusters is calculated as the average of all the similarity scores
of all the pairs $(n_1,n_2)$.

\subsubsection*{{\bf Trainable Threshold T}} In our CC clustering learning model,
we treat the merging threshold $T$ between smaller clusters as a {\em
  trainable parameter} of the model. $T$ is updated after each
iteration in accordance with the criteria defined in the loss function
as any other parameters in the model.

%After having the code change representation vector $v'_c$ for the changed node $n_c$ from the last step, \tool uses hierarchical agglomerative clustering algorithm on top of the $v'_c$ to do the clustering in this step. The hierarchical agglomerative clustering algorithm first regards each changed statement $n_c$ as a separated cluster $CL_c$. Secondly, it calculates the cluster similarity between every two clusters. Thirdly, \tool merges the two clusters that the cluster similarity between them is the largest one, and the cluster similarity is higher than the merging threshold $thres$. Finally, \tool repeats the small steps two and three until there are noclusters that can be merged, and then the left clusters $CL_{pre}$ are the final clustering results in this step.

%During this whole process, we set the merging threshold $thres$ as a trainable parameter, and during the training process, it can automatically get the most suitable value based on the dataset.

%And for the cluster similarity calculation between any two clusters $CL_{c1}$ and $CL_{c2}$, \tool firstly uses the cosine similarity to compute the similarity score $S_{c1,c2}$ between each two elements that are from $CL_{c1}$ and $CL_{c2}$. And then, the \tool calculates the cluster similarity by using the average linkage that is the average of all similarity scores $S_{c1,c2}$.

\subsubsection*{{\bf Loss Function}}

%Within this whole big step, when doing the training, we accept {\mvpdg} as input and ground true clustering results $CL_{label}$ as the training target to train the model. The loss function in training is used to minimize the differences between the predicted clustering results $CL_{pre}$ and $CL_{label}$ to get the most suitable parameters set for the deep learning model.

%When doing training, the ground true clustering results $CL_{label}$ and the predicted clustering results $CL_{pre}$ may have different number of clusters $Cluster_{label}$ and $Cluster_{pre}$. To make the model trainable, we transfer the clustering problem into a classification problem by picking the biggest number of clusters $C_{max} = max($ $Cluster_{label}, Cluster_{pre})$ as the number of classes. \tool uses the zero padding to fill the missed results for the clusters in $CL_{label}$ or $CL_{pre}$. Then \tool uses the cross entropy loss to train the model:

%\begin{equation}\label{new-func}
%	Loss^{*}(X, Y)= \min\limits_{\substack{X_n \in X\\ Y_m \in Y}}(-\sum_{\substack{x_i\in X_n\\ y_j 
%			\in Y_m}}W_ilog\frac{exp(x_i)}{exp(\sum\limits_{x_j \in X_n}x_j)}y_i)
%\end{equation}

%The above cross-entropy loss has been widely used in multi-class classification problems. However, the clustering problem is slightly different from the classification problem because the order of the clusters is not fixed as in the classification problem. So to address this problem, for each pair of predicted clustering results and ground true cluster results $\{x_1, ..., x_{C_{max}}\}$ and $\{y_1,...,y_{C_{max}}\}$, \tool could have $C_{max}!$ different possible orders for both predicted cluster results $X = \{X_1, ..., X_{C_{max}!}\}$ and ground true clustering results $Y = \{Y_1, ..., Y_{C_{max}!}\}$. 

We need to have a loss function that minimizes the differences between
the predicted set of clusters $CL$=$\{CL_1,CL_2, ...,$ $CL_M\}$ and
the correct set $CL_{oracle}$ = $\{Co_{1}, Co_{2},...,
Co_{N}\}$. Because the predicted and correct sets might have different
numbers of clusters ($M \neq N$), we first make them have the same
size $\mathcal{M}$ = $max(M,N)$ by adding the empty clusters to the smaller
set between $CL$ and $CL_{oracle}$.
%
Because we do not know what predicted cluster $CL_i$ in $CL$ is mapped
to a cluster $Co_j$ in the correct set $C_{oracle}$, we consider all
possible orders of the clusters in both $CL$ and $CL_{oracle}$, and
all possible maps between each cluster $CL_i$ and $Co_j$. Note that
the number of clusters is usually small ($\leq$ 6 as reported
in~\cite{nguyen-issre13}), thus, it is manageable to consider all
$\mathcal{M}!$ possible orders in $CL$ and all $\mathcal{M}!$ possible
orders in $C_{oracle}$.

Let us consider an order in $CL$ = $\{CL'_1,..., CL'_{\mathcal{M}}\}$,
and an order in $C_{oracle}$ = $\{Co'_{1},..., Co'_{\mathcal{M}}\}$.
For a changed statement $s_c$ with the corresponding changed node
$n_c$ in {\mvpdg}, we build the 1-hot vector $X$ that represents the
cluster for $n_c$ predicted by the model as follows. If $n_c$ is
predicted to belong to a cluster $CL'_{i}$, the value at the $i$
position of the vector $X$ will be set to 1, otherwise it is set to
0. For example, if $\mathcal{M}$=4, the changed node $n_c$ is
predicted to belong to the cluster $CL'_3$, the vector
$X$=$\{0,0,1,0\}$. A changed statement can belong to multiple
clusters. Similarly, we build the 1-hot vector $Y$ to represent the
correct cluster for $n_c$ in the oracle: if $n_c$ belongs to a cluster
$Co'_{i}$, the value at the $i$ position of the vector $Y$ will be set
to 1, otherwise it is 0.

For a specific order in $CL$ = $\{CL'_1,..., CL'_{\mathcal{M}}\}$, and
a specific order in $C_{oracle}$ = $\{Co'_{1},...,
Co'_{\mathcal{M}}\}$, for a changed node $n_c$, we use the
cross-entropy loss function in the multi-class classification problem as
follows: ($X$=$\{x_1,...,x_{\mathcal{M}}\}$, $Y$=$\{y_1,...,y_{\mathcal{M}}\}$)
\begin{equation}\label{loss-func}
	Loss(X,Y) = -\sum^{\mathcal{M}}_{i=1}W_ilog\frac{exp(x_i)}{exp(\sum^{\mathcal{M}}_{j=1}x_j)}y_i
\end{equation}
To adjust Formula~\ref{loss-func} for our clustering problem, we need
to consider all possible orders in the cluster set $CL$ and those in
$C_{oracle}$. Thus, the cross-entropy loss function
for a changed node $n_c$ of a changed statement $s_c$ is the minimum
value among all the values on the right-hand side of
Formula~\ref{loss-func}. Thus, our loss function is as follows.
\begin{equation}\label{eq6}
	Loss'(X, Y)= \min\limits_{\substack{all (\mathcal{M}!)^{2}\\orders}}(-\sum^{\mathcal{M}}_{i=1}W_ilog\frac{exp(x_i)}{exp(\sum^{\mathcal{M}}_{j=1}x_j)}y_i)
\end{equation}
%The final loss function is the total loss function for all the pairs of the
%cluster $X$ in $CL$ and its corresponding $Y$ in $CL_{oracle}$, and
The loss function for each changed node $n_c$ will be used for
the model to adjust the parameters in the next iteration.

%\begin{equation}\label{eq6}
%	Loss'(X, Y)= \min\limits_{\substack{X_n \in X\\ Y_m \in Y}}(-\sum_{\substack{x_i\in X_n\\ y_j 
%			\in Y_m}}W_ilog\frac{exp(x_i)}{exp(\sum\limits_{x_j \in X_n}x_j)}y_i)
%\end{equation}

\subsubsection*{Predicting/Clustering Process}
After training, we obtain all model's parameters and the trainable
merging threshold. For clustering, {\tool} takes a {\mvpdg} as input
and generates the clusters $CL$.
